Objective DA-10**: Each of the captured AI/ML constituent requirements should be verified.
Objective LM-08**: The applicant should ensure that the estimated bias and variance of the selected model meet the associated learning process management requirements.
Anticipated MOC LM-08**: For the selected model, bias is measured as the mean of the ‚Äòin sample error‚Äô (ùê∏ùëñùëõ), and variance is measured by the statistical variance of the ‚Äòin sample error‚Äô (ùê∏ùëñùëõ). The applicant should analyse the errors on the training data set to identify and mitigate systematic errors.
Objective LM-09**: The applicant should perform an evaluation of the performance of the trained model based on the test data set and document the result of the model verification.
Anticipated MOC LM-09**: The final performance with the test data set should be measured and fed back to the safety assessment process, linking this evaluation to the metrics defined under the Objective SA-01 and explaining any divergence in the metrics compared to the ones used to fulfil Objective LM-04.
Objective LM-10**: The applicant should perform requirements-based verification of the trained model behaviour.
Anticipated MOC LM-10**: Requirements-based testing methods are recommended to reach this objective, focusing on the learning management process requirements (per Objective LM-02) and the subset of requirements allocated to the AI/ML constituent (per Objective DA-02) which can be verified at the level of the trained model. In addition, an analysis should be conducted to confirm the coverage of all requirements by test cases.
Objective LM-11**: The applicant should provide an analysis on the stability of the learning algorithms.
Anticipated MOC LM-11**: As outlined in (EASA and Daedalean, 2020) Section 6.4.1, perturbations in the development phase due to fluctuations in the training data set (e.g. replacement of data points, additive noise or labelling errors) could be a source of instability. Other sources may also be considered such as random initialisation of the model, optimisation methods or hyperparameter tuning. Managing the effects of such perturbations will support the demonstration of the learning algorithm stability and of the learning process repeatability.
Objective LM-12**: The applicant should perform and document the verification of the stability of the trained model, covering the whole AI/ML constituent ODD.
Anticipated MOC LM-12**: The notion of trained model stability is covered through verification cases addressing anticipated perturbations in the operational phase due to fluctuations in the data input (e.g. noise on sensors) and having a possible effect on the trained model output. This activity should address the verification of the trained model stability throughout the ML constituent ODD, including: ‚Äî nominal cases; ‚Äî singular points, edge and corner cases.
Objective LM-13**: The applicant should perform and document the verification of the robustness of the trained model in adverse conditions. Anticipated MOC LM-13: The activity should be supported by test cases, including singular points and edge or corner cases within the ODD (e.g. weather conditions like snow, fog for computer vision).In addition, two additional sets of test cases should be considered: ‚Äî OoD test cases; ‚Äî ‚Äòadversarial‚Äô test cases consisting in defining cases that are not based on the requirements but that may affect the AI/ML constituent expected behaviour. The use of formal methods is anticipated to be a promising MOC with this objective, although in the current state of research those methods appear to be limited to local evaluations. Formal methods could, for example, be used for identifying ‚Äòadversarial‚Äô test cases. Recent tools that are based on optimisation algorithms (e.g. MILP) could be used to mimic an adversary searching for an input attacking the ML model. Once identified, these ‚Äòadversarial‚Äô inputs could be added to the collected data set, so that the ML model is retrained on an augmented data set to increase its robustness.
Objective LM-14**: The applicant should verify the anticipated generalisation bounds using the test data set.
Anticipated MOC LM-14**: Evidence of the validity of the anticipated generalisation bounds proposed to fulfil Objective LM-04 should be recorded.
Objective LM-15**: the applicant should capture the description of the resulting ML model.
Objective IMP-01**: The applicant should capture the requirements pertaining to the ML model implementation process.
Anticipated MOC IMP-01**: Those requirements include but are not limited to: ‚Äî AI/ML constituents requirements pertaining to the implementation process  C.3.1.2.1); ‚Äî requirements originating from the learning requirements capture (C.3.1.4), such as the expected performance of the inference model with the test data set; ‚Äî data processing requirements originating from the data management process (C.3.1.2.1); ‚Äî requirements pertaining to the conversion of the model to be compatible with the target platform; ‚Äî requirements pertaining to the optimisation of the model to adapt to the target platform resources; ‚Äî requirements pertaining to the expected tolerances for comparison of the inference model outputs with the trained model outputs; ‚Äî requirements pertaining to the development of the inference model into software and/or hardware items, such as processing power, parallelisation, latency, worst-case execution time (WCET), and memory.
Objective IMP-02**: The applicant should validate the model description captured under Objective LM-15 as well as each of the requirements captured under Objective IMP-01.
Objective IMP-03**: The applicant should document evidence that all derived requirements generated through the model implementation process have been provided to the (sub)system processes, including the safety (support) assessment.
Objective IMP-04**: Any post-training model transformation (conversion, optimisation) should be identified and validated for its impact on the model behaviour and performance, and the environment (i.e. software tools and hardware) necessary to perform model transformation should be identified.
Anticipated MOC IMP-04-1**: Identification of the different conversion steps and confirmation that no impact on the model behaviour is foreseen. In addition, the applicant should describe the environment for each transformation step, and any associated assumptions or limitations should be captured and validated.
Anticipated MOC IMP-04-2**: Identification of the different optimisation steps performed during implementation and confirmation that no impact on the model behaviour is foreseen, taking into account the expected tolerances (identified per Objective IMP-01). In addition, the applicant should describe the environment for each transformation step, and any associated assumptions or limitations should be captured and validated.
Objective IMP-05**: The applicant should plan and execute appropriate development assurance processes to develop the inference model into software and/or hardware items.
Anticipated MOC IMP-05**: ‚Äî For software aspects, it is anticipated that the provisions of applicable software development assurance guidance (e.g. AMC 20-115D for product certification projects) would provide the necessary means to confirm that Objective IMP-05 is fulfilled. This guidance may need to be complemented to address specific issues linked to the implementation of an ML model into software, such as memory management issues. ‚Äî For hardware aspects, it is anticipated that the provisions of applicable hardware development assurance guidance (e.g. AMC 20-152A for product certification projects) would provide the necessary means to confirm that Objective IMP-05 is fulfilled. FPGAs, ASICs and COTS architectures are covered by the existing guidance; however, other ML architectures, such as graphics processing units (GPUs and other AI accelerators), have specificities that are not accounted for in the existing guidance (e.g. very complex interference mechanisms or non-deterministic pipelining). Specific hardware architectures like GPUs will require specific guidance to be developed. ‚Äî For multicore processor (MCP) aspects, it is anticipated that the provisions of applicable MCP development assurance guidance (e.g. AMC 20-193 for product certification projects) would provide the necessary means to confirm that Objective IMP-05 is fulfilled.
Objective IMP-06**: The applicant should verify that any transformation (conversion, optimisation, inference model development) performed during the trained model implementation step has not adversely altered the defined model properties.
Anticipated MOC IMP-06**: As a preliminary step, a set of model properties that are expected to be preserved should be captured. The use of specific verification methods (e.g. formal methods) is expected to be necessary to comply with this objective, taking into account the performance metrics and the expected tolerances (identified per Objective IMP-01).
Objective IMP-07**: The differences between the software and hardware of the platform used for model training and those used for the inference model verification should be identified and assessed for their possible impact on the inference model behaviour and performance.
Anticipated MOC IMP-07**: The analysis of the differences, such as the ones induced by the choice of mathematical libraries or ML framework, is an important means to reach this objective. This objective does not apply when the complete verification of the ML model properties is performed with the inference model on the target platform.
Objective IMP-08**: The applicant should perform an evaluation of the performance of the inference model based on the test data set and document the result of the model verification.
Anticipated MOC IMP-08**: The final performance with the test data set should be measured and fed back to the safety assessment process, linking this evaluation to the metrics defined under the Objective SA-01 and explaining any divergence in the metrics compared to the ones used to fulfil Objective LM-09.
Objective IMP-09**: The applicant should perform and document the verification of the stability of the inference model.
Anticipated MOC IMP-09**: The notion of inference model stability is covered through verification cases addressing anticipated perturbations in the operational phase due to fluctuations in the data input (e.g. noise on sensors) and having a possible effect on the inference model output. This activity should address the verification of the inference model stability throughout the ML constituent ODD, including: ‚Äî nominal cases; ‚Äî singular points, edge and corner cases.
Objective IMP-10**: The applicant should perform and document the verification of the robustness of the inference model in adverse conditions.
Anticipated MOC IMP-10**: The activity should be supported by test cases, including edge or corner cases within the ODD (e.g. weather conditions like snow, fog for computer vision) and OoD test cases. The refinement of this anticipated MOC is expected to benefit from the MLEAP project deliverables.
Objective IMP-11**: The applicant should perform requirements-based verification of the inference model behaviour when integrated into the AI/ML constituent.
Anticipated MOC IMP-11**: Requirements-based testing methods are necessary to reach this objective, focusing on the requirements pertaining to the implementation (per Objective IMP-01) as well as all requirements allocated to the AI/ML constituent (per Objective DA-02). In addition, an analysis should be conducted to confirm the coverage of all requirements by verification cases. The test environment should at least foresee: ‚Äî the AI/ML constituent integrated on the target platform (environment #1), ‚Äî the AI/ML constituent integrated in its subsystem, with representative interfaces to the other subsystems, including to the directly interfacing sensors (environment #2).
Objective DM-08**: The applicant should perform a data verification step to confirm the appropriateness of the defined ODD and of the data sets used for the training, validation and verification of the ML model.
Anticipated MOC DM-08**: The associated activities include verification of: ‚Äî the correct identification of the input space; ‚Äî reassessment of the defined ODD; ‚Äî compliance of the data sets (training, validation, test) with the data management requirements; ‚Äî coverage of the whole ODD by the test data set, with the necessary level of completeness and representativeness.
Objective LM-16**: The applicant should confirm that the trained model verification activities are complete.
Anticipated MOC LM-16**: The associated activities include verification of: ‚Äî correctness of requirements-based verification procedures; ‚Äî correctness of requirements-based verification results, and justification of discrepancies; ‚Äî coverage of the AI/ML constituent requirements by verification methods; ‚Äî evaluation of the trained model performance, with a coverage of all pairs of ODD parameters; ‚Äî coverage of the whole AI/ML constituent ODD when ensuring stability of the trained model.
Objective IMP-12**: The applicant should confirm that the AI/ML constituent verification activities are complete.
Anticipated MOC IMP-12**: The associated activities include verification of: ‚Äî correctness of the requirements-based verification procedures; ‚Äî correctness of requirements-based verification results, and justification of discrepancies; ‚Äî coverage of the AI/ML constituent requirements by verification methods; ‚Äî evaluation of the AI/ML constituent performance, with a coverage of all pairs of ODD parameters.
Objective CM-01**: The applicant should apply all configuration management principles to the AI/ML constituent life-cycle data, including but not limited to: ‚Äî identification of configuration items; ‚Äî versioning; ‚Äî baselining; ‚Äî change control; ‚Äî reproducibility; ‚Äî problem reporting; ‚Äî archiving and retrieval, and retention period.
Anticipated MOC CM-01**: The collected data, the training, validation, and test data sets used for the frozen model, as well as all the tooling used during the transformation of the data are to be managed as configuration items.
Objective QA-01**: The applicant should ensure that quality/process assurance principles are applied to the development of the AI-based system, with the required independence level.
Objective RU-01**: The applicant should perform an impact assessment of the reuse of a trained ML model before incorporating the model into an AI/ML constituent. The impact assessment should consider: ‚Äî alignment and compatibility of the intended behaviours of the ML models; ‚Äî alignment and compatibility of the ODDs; ‚Äî compatibility of the performance of the reused ML model with the performance requirements expected for the new application; ‚Äî availability of adequate technical documentation (e.g. equivalent documentation depending on the required assurance level); ‚Äî possible licensing or legal restrictions on the reused ML model (more particularly in the case of COTS ML models); and ‚Äî evaluation of the required development level.
Objective RU-02**: The applicant should perform a functional analysis of the COTS ML model to confirm its adequacy to the requirements and architecture of the AI/ML constituent.
Objective RU-03**: The applicant should perform an analysis of the unused functions of the COTS ML model, and prepare the deactivation of these unused functions.
Objective SU-01**: The applicant should capture the accuracy and fidelity of the reference model in order to support the verification of the accuracy of the surrogate model.
Objective SU-02**: the applicant should identify, document and mitigate the additional sources of uncertainties linked with the use of a surrogate model.
Objective EXP-01**: The applicant should identify the list of stakeholders, other than end users, that need explainability of the AI-based system at any stage of its life cycle, together with their roles, their responsibilities and their expected expertise (including assumptions made on the level of training, qualification and skills).
Objective EXP-02**: For each of these stakeholders (or groups of stakeholders), the applicant should characterise the need for explainability to be provided, which is necessary to support the development and learning assurance processes.
Anticipated MOC EXP-02**: The need for explainability should at least support the following goals: ‚Äî Strengthening the input-output link; ‚Äî Detection of residual bias in the trained and/or inference model; and ‚Äî Absence of unintended behaviours.
Objective EXP-03**: The applicant should identify and document the methods at AI/ML item and/or output level satisfying the specified AI explainability needs.
Objective EXP-04**: The applicant should design the AI-based system with the ability to deliver an indication of the level of confidence in the AI/ML constituent output, based on actual measurements or on quantification of the level of uncertainty.
Objective EXP-05**: The applicant should design the AI-based system with the ability to monitor that its inputs are within the specified ODD boundaries (both in terms of input parameter range and distribution) in which the AI/ML constituent performance is guaranteed.
Objective EXP-06**: The applicant should design the AI-based system with the ability to monitor that its outputs are within the specified operational AI/ML constituent performance boundaries.
Objective EXP-07**: The applicant should design the AI-based system with the ability to monitor that the AI/ML constituent outputs (per Objective EXP-04) are within the specified operational level of confidence.
Anticipated MOC EXP-07**: Assuming that the decisions, actions, or diagnoses provided by an AI- based system may not always be fully reliable, the AI-based system should compute a level of confidence in its outputs. Such an indication should be part of the elements provided within the explanations as needed.
Objective EXP-08**: The applicant should ensure that the output of the specified monitoring per the previous three objectives are in the list of data to be recorded per MOC EXP-09-2.
Objective EXP-09**: The applicant should provide the means to record operational data that is necessary to explain, post operations, the behaviour of the AI-based system and its interactions with the end user, as well as the means to retrieve this data.
Anticipated MOC EXP-09-1**: The recording should automatically start before or when the AI-based system is operating, and it should continue while the AI-based system is operating. The recording should automatically stop when or after the AI-based system is no longer operating.
Anticipated MOC EXP-09-2**: The recorded data should contain sufficient information to detect deviations from the expected behaviour of the AI-based system, whether it operated alone or interacting with an end user. In addition, this information should be sufficient: (a) to accurately determine the nature of each individual deviation, its time and the amplitude/severity of that individual deviation (when applicable); (b) to reconstruct the chronological sequence of inputs to and outputs from the AI-based system during the deviation, and to the extent possible, before the deviation; (c) for monitoring trends regarding deviations over longer periods of time.
Anticipated MOC EXP-09-3**: The means to retrieve the recorded data should be provided to those entitled to access and use it in a way so that they can perform an effective monitoring of the safety of AI-based system operations. This includes: (a) (b) (c) timely and complete access to the data needed for that purpose; access to the tools and documentation necessary to convert the recorded data in a format that is understandable and appropriate for human analysis; possibility to gather the recorded data over longer periods of time and possibility to automatically process part of this data for trend analyses and statistical studies.
Anticipated MOC EXP-09-4**: The recorded data should contain sufficient information to accurately reconstruct the operation of the AI-based system and its interactions with the end user before an accident or incident. In particular, this information should be sufficient to: (a) accurately reconstruct the chronological sequence of inputs to and outputs from the AI- based system; (b) identify when communication or cooperation/collaboration between the AI-based system and the end user was degraded. This may require recording additional communications of the end user with other HAT members or with other organisations (including voice communications), or recording additional actions performed by the end user at their workstation (for instance, by means of images), as necessary; identify any unexpected behaviour of the AI-based system that is relevant for explaining the accident or incident.
Anticipated MOC EXP-09-5**: The data should be recorded in a way so that it can be retrieved and used after an accident or an incident. This includes: (a) (b) (c) (d) if the AI-based system is airborne, a crashworthy memory medium on board the aircraft; recording technology that is reliable and capable of retaining data for long periods of time without electrical power supply; if the AI-based system is airborne, means to facilitate the retrieval of the data from the memory medium after an accident (e.g. means to locate the accident scene and the memory media, tools to retrieve data from damaged memory media) or an incident; provision of tools and documentation necessary to convert the recorded data in a format that is understandable and appropriate for human analysis.