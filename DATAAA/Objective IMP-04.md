**Identity and Purpose Checklist**
=============================

### Data Management (DM)

#### Validation and Verification of Data

* Has the applicant validated and verified the data throughout the data management process? **[YES/NO]**
* Are the data management requirements addressed? **[YES/NO]**

#### Data Verification Step

* Is a data verification step performed to confirm the appropriateness of the defined ODD and data sets used for training, validation, and verification? **[YES/NO]**

### Machine Learning (LM)

#### ML Model Architecture

* Is the ML model architecture described? **[YES/NO]**

#### Learning Management and Training Processes

* Are the requirements pertaining to learning management and training processes captured? **[YES/NO]**
	+ Model family and model selection: **[YES/NO]**
	+ Learning algorithm(s) selection: **[YES/NO]**
	+ Explainability capabilities of the selected model: **[YES/NO]**
	+ Activation functions: **[YES/NO]**
	+ Cost/loss function selection describing the link to performance metrics: **[YES/NO]**
	+ Model bias and variance metrics and acceptable levels: **[YES/NO]**
	+ Model robustness and stability metrics and acceptable levels: **[YES/NO]**
	+ Training environment (hardware and software) identification: **[YES/NO]**
	+ Model parameters initialisation strategy: **[YES/NO]**
	+ Hyper-parameters identification and setting: **[YES/NO]**
	+ Expected performance with training, validation, and test sets: **[YES/NO]**

#### Credit Sought from Training Environment

* Is the credit sought from the training environment documented? **[YES/NO]**

#### Quantifiable Generalisation Bounds

* Are quantifiable generalisation bounds provided? **[YES/NO]**

#### Model Training Documentation

* Is the result of model training documented? **[YES/NO]**

#### Model Optimisation and Its Impact

* Is any model optimisation (e.g. pruning, quantization) documented, and its impact on model behavior or performance assessed? **[YES/NO]**

### Reviewer Checklist

**Data Management (DM)**

* Has the applicant validated and verified the data throughout the data management process? **[YES/NO]**
* Are the data management requirements addressed? **[YES/NO]**
* Is a data verification step performed to confirm the appropriateness of the defined ODD and data sets used for training, validation, and verification? **[YES/NO]**

**Machine Learning (LM)**

* Is the ML model architecture described? **[YES/NO]**
* Are the learning management and training processes requirements captured? **[YES/NO]**
	+ Model family and model selection: **[YES/NO]**
	+ Learning algorithm(s) selection: **[YES/NO]**
	+ Explainability capabilities of the selected model: **[YES/NO]**
	+ Activation functions: **[YES/NO]**
	+ Cost/loss function selection describing the link to performance metrics: **[YES/NO]**
	+ Model bias and variance metrics and acceptable levels: **[YES/NO]**
	+ Model robustness and stability metrics and acceptable levels: **[YES/NO]**
	+ Training environment (hardware and software) identification: **[YES/NO]**
	+ Model parameters initialisation strategy: **[YES/NO]**
	+ Hyper-parameters identification and setting: **[YES/NO]**
	+ Expected performance with training, validation, and test sets: **[YES/NO]**

### Additional Requirements

* Is the bias-variance trade-off in model family selection accounted for? **[YES/NO]**
* Are quantifiable generalisation bounds provided? **[YES/NO]**
* Is the result of model training documented? **[YES/NO]**
* Is any model optimisation (e.g. pruning, quantization) documented, and its impact on model behavior or performance assessed? **[YES/NO]**