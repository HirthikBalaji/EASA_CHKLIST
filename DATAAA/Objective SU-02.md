Here is the checklist generated for the author and reviewer of the Artificial Intelligence-Machine Learning software:

**Configuration Management (CM)**

* Have you identified configuration items related to AI/ML constituent life-cycle data?
	+ [ ] Yes
	+ [ ] No
* Are versioning, baselining, change control, reproducibility, problem reporting, archiving and retrieval, and retention period applied to the AI/ML constituent life-cycle data?
	+ [ ] Yes
	+ [ ] No

**Quality Assurance (QA)**

* Have you ensured that quality/process assurance principles are applied to the development of the AI-based system with the required independence level?
	+ [ ] Yes
	+ [ ] No

**Reuse of Trained ML Model (RU)**

* Have you performed an impact assessment of the reuse of a trained ML model before incorporating it into an AI/ML constituent?
	+ [ ] Yes
	+ [ ] No
* Have you confirmed that the COTS ML model is adequate to the requirements and architecture of the AI/ML constituent through functional analysis?
	+ [ ] Yes
	+ [ ] No
* Have you deactivated unused functions of the COTS ML model?
	+ [ ] Yes
	+ [ ] No

**Surrogate Model (SU)**

* Have you captured the accuracy and fidelity of the reference model to support verification of the accuracy of the surrogate model?
	+ [ ] Yes
	+ [ ] No
* Have you identified, documented, and mitigated additional sources of uncertainties linked with the use of a surrogate model?
	+ [ ] Yes
	+ [ ] No

**Explainability (EXP)**

* Have you identified stakeholders other than end users that need explainability of the AI-based system at any stage of its life cycle, including their roles, responsibilities, and expected expertise?
	+ [ ] Yes
	+ [ ] No
* Have you characterized the need for explainability to be provided for each stakeholder or group of stakeholders?
	+ [ ] Yes
	+ [ ] No
* Have you identified methods at AI/ML item and/or output level satisfying the specified AI explainability needs?
	+ [ ] Yes
	+ [ ] No
* Does the AI-based system have the ability to deliver an indication of the level of confidence in the AI/ML constituent output based on actual measurements or quantification of uncertainty?
	+ [ ] Yes
	+ [ ] No
* Does the AI-based system monitor its inputs are within specified operational boundaries (both in terms of input parameter range and distribution) in which the AI/ML constituent performance is guaranteed?
	+ [ ] Yes
	+ [ ] No
* Does the AI-based system monitor its outputs are within specified operational performance boundaries?
	+ [ ] Yes
	+ [ ] No
* Does the AI-based system monitor that its AI/ML constituent outputs (per Objective EXP-04) are within specified operational level of confidence?
	+ [ ] Yes
	+ [ ] No

Let me know if you'd like me to make any changes!